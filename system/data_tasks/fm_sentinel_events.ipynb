{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import sys\n",
    "\n",
    "from data_task_helpers import something\n",
    "\n",
    "something()\n",
    "\n",
    "from api_data_task_executioner.data_task_tools import assert_dte_tools_available, get_resolved_parameters_for_connection, initialise_data_task, find_json_arg  # noqa: E402\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "environment = initialise_data_task(\"QE Data Task Running\", params=params)\n",
    "params[\"name\"] = params.get(\"customname\", params.get(\"name\", \"No parameters given!\"))\n",
    "params[\"sleep_time\"] = params.get(\"sleep_time\", 0.2)\n",
    "\n",
    "if not params:\n",
    "    environment.log_error(\"No parameters given!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jaydebeapi\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sqlalchemy import create_engine, text\n",
    "from jaydebeapi import Connection\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Source and Destinaton Database Connections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_environment = get_resolved_parameters_for_connection(\"EPMS_Source\")\n",
    "destination_environment = get_resolved_parameters_for_connection(\"EPMS_Destination\")\n",
    "\n",
    "environment.log_message(f'Finished setting source and destination connections')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Filemaker Driver Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_jar_path = \"fmjdbc.jar\"\n",
    "driver_class = \"com.filemaker.jdbc.Driver\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process File Maker Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file_maker_connection():\n",
    "    try:\n",
    "        server = source_environment.get(\"server\")\n",
    "        username = source_environment.get(\"username\")\n",
    "        password = source_environment.get(\"password\")\n",
    "        return jaydebeapi.connect(driver_class, server, [username, password], driver_jar_path)\n",
    "    except Exception as ex:\n",
    "        return None\n",
    "\n",
    "\n",
    "def close_file_maker_connection(con: Connection):\n",
    "    if con is not None:\n",
    "        con.close()\n",
    "\n",
    "\n",
    "def fetch_file_maker_data(query: str, con: Connection):\n",
    "    cursor = con.cursor()\n",
    "    cursor.execute(query)\n",
    "    data_rows = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    return data_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open connection to FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_connection = open_file_maker_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dim_patient Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_confs = {\n",
    "    \"query\": \"SELECT  r.name, d.name, f.name, f.code, p.id, p.sex, p.dob, p.maritalStatus, p.patientStatus, p.clientCode, pharmacyNumber, pmtctNumber, nameFirst, nameLast, phoneCellNumber, phoneAltNumber, p.ageYear, resCurrentAddTown, resCurrentAddConstituency, resCurrentAddStreet, resPermanentAddTown, resPermanentAddConstituency, resPermanentAddStreet, idFacilityCurrent, tsName, tsCellPhoneNumber, tsSecondName, tsSecondCellPhoneNumber,  homeBasedCareOrg, homeBasedCareCode,  deathDate  FROM pat p LEFT join fac f on p.idFacilityCurrent = f.id  LEFT join region r on f.idregion=r.id LEFT join district d on f.idDistrict = d.id\",\n",
    "    \"cols\": ['region','district','current_facility', 'facility_code','client_id', 'sex', 'date_of_birth', 'marital_status','patient_status','client_code', 'pharmacy_code','pmtct_number', 'first_name','last_name','contact_number','alt_contact_number','age','current_town','current_constituency','current_street', 'permanent_town','permanent_constituency','permanent_street','id_facility_current', 'ts_name', 'ts_cell_phone_number', 'ts_second_name', 'ts_second_cell_phone_number', 'cbart_cargs_name', 'cbart_cargs_code', 'death_date']\n",
    "}\n",
    "\n",
    "patient_query = patient_confs.get(\"query\")\n",
    "patient_cols = patient_confs.get(\"cols\")\n",
    "\n",
    "patient_data = fetch_file_maker_data(patient_query, fm_connection)\n",
    "dim_pat_df = pd.DataFrame(patient_data, columns=patient_cols)\n",
    "\n",
    "dim_pat_df['date_of_birth'] = pd.to_datetime(dim_pat_df['date_of_birth'], errors='coerce')\n",
    "dim_pat_df['first_name'] = 'FName'\n",
    "dim_pat_df['last_name'] = 'LName'\n",
    "dim_pat_df['contact_number'] = '123456'\n",
    "dim_pat_df['alt_contact_number'] = '123456'\n",
    "dim_pat_df['ts_name'] = 'TS_Name'\n",
    "dim_pat_df['ts_second_name'] = 'TS_Second_Name'\n",
    "dim_pat_df['ts_cell_phone_number'] = 'TS_Phone'\n",
    "dim_pat_df['ts_second_cell_phone_number'] = 'TS_Second_Phone'\n",
    "\n",
    "dim_pat_df['sex'] = dim_pat_df['sex'].fillna('Unknown')\n",
    "\n",
    "dim_pat_df.head()\n",
    "\n",
    "environment.log_message(f'Finished extracting client data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get patient latest transfer status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_tsfr_confs = {\n",
    "    \"query\": \"SELECT idpatient,  status, \\\"date\\\" FROM tsfr\",\n",
    "    \"cols\": ['client_id' ,'transfer_status', 'transfer_date']\n",
    "}\n",
    "\n",
    "fact_tsfr_query = fact_tsfr_confs.get(\"query\")\n",
    "fact_tsfr_cols = fact_tsfr_confs.get(\"cols\")\n",
    "\n",
    "fact_tsfr_data = fetch_file_maker_data(fact_tsfr_query, fm_connection)\n",
    "fact_tsfr_df = pd.DataFrame(fact_tsfr_data, columns=fact_tsfr_cols)\n",
    "\n",
    "fact_tsfr_df = fact_tsfr_df.dropna(subset=['transfer_date'])\n",
    "\n",
    "fact_tsfr_df = fact_tsfr_df.loc[fact_tsfr_df.groupby('client_id')['transfer_date'].idxmin()].reset_index(drop=True)\n",
    "fact_tsfr_df.head()\n",
    "\n",
    "fact_tsfr_df.head(100)\n",
    "\n",
    "environment.log_message(f'Finished extracting client transfer status data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add transfer status to patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_pat_df = pd.merge(dim_pat_df, fact_tsfr_df, on='client_id', how='left')\n",
    "\n",
    "dim_pat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get first Weight and WHO Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_meas_confs = {\n",
    "    \"query\": \"SELECT idpatient, weight, whoStage,\\\"Date\\\" FROM Meas m\",\n",
    "    \"cols\": ['client_id', 'weight','who_stage', 'creation_date']\n",
    "}\n",
    "\n",
    "fact_meas_query = fact_meas_confs.get(\"query\")\n",
    "fact_meas_cols = fact_meas_confs.get(\"cols\")\n",
    "\n",
    "fact_meas_data = fetch_file_maker_data(fact_meas_query, fm_connection)\n",
    "fact_meas_df = pd.DataFrame(fact_meas_data, columns=fact_meas_cols)\n",
    "\n",
    "fact_meas_df = fact_meas_df.dropna(subset=['creation_date'])\n",
    "\n",
    "fact_meas_df = fact_meas_df.loc[fact_meas_df.groupby('client_id')['creation_date'].idxmin()].reset_index(drop=True)\n",
    "fact_meas_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create fact_hiv_diagnosis Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_hiv_diagnosis_confs = {\n",
    "    \"query\": \"SELECT idpatient, hivconfirmationdate, hivconfirmatoryresultsdate, hivconfirmatoryresultstype, idfacilitycreate, fullDisclosureDAte FROM Cd\",\n",
    "    \"cols\": ['client_id', 'hiv_confirmation_date','hiv_confirmatory_result_date', 'hiv_confirmatory_result_type', 'hiv_diagnosis_facility_id','full_disclosure_date']\n",
    "}\n",
    "\n",
    "fact_hiv_diagnosis_query = fact_hiv_diagnosis_confs.get(\"query\")\n",
    "fact_hiv_diagnosis_cols = fact_hiv_diagnosis_confs.get(\"cols\")\n",
    "\n",
    "fact_hiv_diagnosis_data = fetch_file_maker_data(fact_hiv_diagnosis_query, fm_connection)\n",
    "fact_hiv_diagnosis_df = pd.DataFrame(fact_hiv_diagnosis_data, columns=fact_hiv_diagnosis_cols)\n",
    "\n",
    "fact_hiv_diagnosis_df['hiv_confirmation_date'] = pd.to_datetime(fact_hiv_diagnosis_df['hiv_confirmation_date'], errors='coerce')\n",
    "fact_hiv_diagnosis_df['hiv_confirmatory_result_date'] = pd.to_datetime(fact_hiv_diagnosis_df['hiv_confirmatory_result_date'], errors='coerce')\n",
    "\n",
    "fact_hiv_diagnosis_df = fact_hiv_diagnosis_df.dropna(subset=['hiv_confirmation_date'])\n",
    "\n",
    "fact_hiv_diagnosis_df = fact_hiv_diagnosis_df.loc[fact_hiv_diagnosis_df.groupby('client_id')['hiv_confirmation_date'].idxmin()].reset_index(drop=True)\n",
    "\n",
    "fact_hiv_diagnosis_df.head()\n",
    "\n",
    "environment.log_message(f'Finished extracting HIV diagnosis data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Initial weight and WHO Stage to fact_hiv_diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_hiv_diagnosis_df = pd.merge(fact_hiv_diagnosis_df, fact_meas_df[['client_id','weight', 'who_stage']], on='client_id', how='left')\n",
    "\n",
    "fact_hiv_diagnosis_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add dim_patient, fact_hiv_diagnosis to fact_sentinel_event dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_sentinel_event_df = pd.merge(dim_pat_df, fact_hiv_diagnosis_df, on='client_id', how='left')\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create hiv_enrolment dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fact_hiv_enrolment_confs = {\n",
    "    \"query\": \"SELECT c.idpatient, c.idfacilitycreate, c.hivenrolleddate, c.disclosureenrollmentdate, c.arteligiblereason, c.artstartdate, p.artnumber, p.artnumber, p.artnumberlegacy, c.idfacilityARTStart FROM pat p LEFT JOIN Cd c ON p.id=c.idpatient\",\n",
    "    \"cols\": ['client_id', 'hiv_enrollment_facility_id', 'hiv_enrollment_date', 'hiv_disclosure_enrollment_date','art_eligible_reason','art_start_date', 'quantum_number' , 'art_number', 'art_number_legacy', 'arv_initiating_facility']\n",
    "}\n",
    "\n",
    "\n",
    "fact_hiv_enrolment_query = fact_hiv_enrolment_confs.get(\"query\")\n",
    "fact_hiv_enrolment_cols = fact_hiv_enrolment_confs.get(\"cols\")\n",
    "\n",
    "fact_hiv_enrolment_data = fetch_file_maker_data(fact_hiv_enrolment_query, fm_connection)\n",
    "fact_hiv_enrolment_df = pd.DataFrame(fact_hiv_enrolment_data, columns=fact_hiv_enrolment_cols)\n",
    "\n",
    "fact_hiv_enrolment_df['hiv_enrollment_date'] = pd.to_datetime(fact_hiv_enrolment_df['hiv_enrollment_date'], errors='coerce')\n",
    "fact_hiv_enrolment_df['hiv_disclosure_enrollment_date'] = pd.to_datetime(fact_hiv_enrolment_df['hiv_disclosure_enrollment_date'], errors='coerce')\n",
    "fact_hiv_enrolment_df['art_start_date'] = pd.to_datetime(fact_hiv_enrolment_df['art_start_date'], errors='coerce')\n",
    "\n",
    "fact_hiv_enrolment_df = fact_hiv_enrolment_df.dropna(subset=['hiv_enrollment_date'])\n",
    "\n",
    "fact_hiv_enrolment_df = fact_hiv_enrolment_df.loc[fact_hiv_enrolment_df.groupby('client_id')['hiv_enrollment_date'].idxmin()].reset_index(drop=True)\n",
    "\n",
    "fact_hiv_enrolment_df.head()\n",
    "\n",
    "environment.log_message(f'Finished extracting HIV enrolment data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add fact_hiv_enrolment to fact_sentinel_event dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fact_sentinel_event_df = pd.merge(fact_sentinel_event_df, fact_hiv_enrolment_df, on='client_id', how='left')\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get first and last visit ids per patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_visits_confs = {\n",
    "    \"query\": \"SELECT id, idpatient, visitDate FROM Fup\",\n",
    "    \"cols\": ['id', 'client_id', 'visit_date' ]\n",
    "}\n",
    "\n",
    "fact_visits_query = fact_visits_confs.get(\"query\")\n",
    "fact_visits_cols = fact_visits_confs.get(\"cols\")\n",
    "\n",
    "fact_visits_data = fetch_file_maker_data(fact_visits_query, fm_connection)\n",
    "fact_visits_df = pd.DataFrame(fact_visits_data, columns=fact_visits_cols)\n",
    "\n",
    "latest_visits_df = fact_visits_df.loc[fact_visits_df.groupby('client_id')['visit_date'].idxmax()]\n",
    "\n",
    "first_visits_df = fact_visits_df.loc[fact_visits_df.groupby('client_id')['visit_date'].idxmin()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create first_fact_visits dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_visits_confs = {\n",
    "    \"query\": \"SELECT DISTINCT f.idpatient, f.idfacilitycreate, f.visitDate FROM Fup f\",\n",
    "    \"cols\": ['client_id', 'visit_facility_id', 'visit_date']\n",
    "}\n",
    "\n",
    "fact_visits_query = fact_visits_confs.get(\"query\")\n",
    "fact_visits_cols = fact_visits_confs.get(\"cols\")\n",
    "\n",
    "ids = first_visits_df['id'].tolist()\n",
    "\n",
    "ids_str = ','.join(f\"'{id_}'\" for id_ in ids)\n",
    "\n",
    "fact_visits_query_updated = f\"{fact_visits_query} WHERE f.id IN ({ids_str})\"\n",
    "\n",
    "fact_visits_data = fetch_file_maker_data(fact_visits_query_updated, fm_connection)\n",
    "fact_first_visit_df = pd.DataFrame(fact_visits_data, columns=fact_visits_cols)\n",
    "\n",
    "fact_first_visit_df['visit_date'] = pd.to_datetime(fact_first_visit_df['visit_date'], errors='coerce')\n",
    "\n",
    "fact_first_visit_df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add first visit info to fact_sentinel_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_add = {\n",
    "    'visit_date': 'first_visit_date', \n",
    "    'visit_facility_id': 'first_visit_facility_id'\n",
    "}\n",
    "\n",
    "fact_first_visit_df = fact_first_visit_df[list(columns_to_add.keys()) + ['client_id']].rename(columns=columns_to_add)\n",
    "\n",
    "fact_sentinel_event_df = pd.merge(fact_sentinel_event_df, fact_first_visit_df, on='client_id', how='left')\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create fact_last_visit dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_visits_confs = {\n",
    "    \"query\": \"SELECT DISTINCT f.idpatient, f.idfacilitycreate, f.visitDate, f.followupDate, f.scheduledDate, f.careModel, f.pregnantstatus, f.Breastfeeding, f.pregnantlmp, f.pregnantedd, f.ctxadherence, f.arvadherence, cc.treatment, cc.dateTreatment, labResult, pf.stiGenitalUlcers, pf.stiVaginalUrethralDischarge, pf.stiScreenResult, f.oiDetail, f.oiOther, f.tbScreenResult FROM Fup f LEFT JOIN patFup pf on f.id=pf.id LEFT JOIN cc ON f.id=cc.idFollowUp\",\n",
    "    \"cols\": ['client_id', 'visit_facility_id', 'visit_date', 'next_visit_date', 'scheduled_visit_date', 'care_model', 'pregnancy_status', 'breast_feeding', 'lmp', 'edd', 'ctx_adherence', 'arv_adherence', 'cc_treatment_type','cc_treatment_date','cc_results', 'genital_ulcers','vaginal_urethral_discharge','sti_screening_result', 'oi', 'oi_other','tb_screen_result' ]\n",
    "}\n",
    "\n",
    "fact_visits_query = fact_visits_confs.get(\"query\")\n",
    "fact_visits_cols = fact_visits_confs.get(\"cols\")\n",
    "\n",
    "ids = latest_visits_df['id'].tolist()\n",
    "\n",
    "ids_str = ','.join(f\"'{id_}'\" for id_ in ids)\n",
    "\n",
    "fact_visits_query_updated = f\"{fact_visits_query} WHERE f.id IN ({ids_str})\"\n",
    "\n",
    "fact_visits_data = fetch_file_maker_data(fact_visits_query_updated, fm_connection)\n",
    "fact_last_visit_df = pd.DataFrame(fact_visits_data, columns=fact_visits_cols)\n",
    "\n",
    "fact_last_visit_df['visit_date'] = pd.to_datetime(fact_last_visit_df['visit_date'], errors='coerce')\n",
    "fact_last_visit_df['next_visit_date'] = pd.to_datetime(fact_last_visit_df['next_visit_date'], errors='coerce')\n",
    "\n",
    "fact_last_visit_df['care_model'] = fact_last_visit_df['care_model'].fillna('Unknown')\n",
    "\n",
    "fact_last_visit_df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add last visit info to fact_sentinel_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_add = {\n",
    "    'visit_date': 'last_visit_date',\n",
    "    'next_visit_date': 'last_next_visit_date', \n",
    "    'scheduled_visit_date': 'last_scheduled_visit_date', \n",
    "    'pregnancy_status': 'last_pregnancy_status', \n",
    "    'breast_feeding': 'last_breast_feeding', \n",
    "    'lmp': 'last_lmp', \n",
    "    'edd': 'last_edd',\n",
    "    'care_model': 'last_care_model',\n",
    "    'visit_facility_id': 'last_visit_facility_id',\n",
    "    'cc_treatment_type':'last_cc_treatment_type',\n",
    "    'cc_treatment_date': 'last_cc_treatment_date',\n",
    "    'cc_results': 'last_cc_results',\n",
    "    'oi':'last_oi', \n",
    "    'oi_other': 'last_oi_other',\n",
    "    'tb_screen_result': 'last_tb_screen_result'\n",
    "}\n",
    "\n",
    "fact_last_visit_df = fact_last_visit_df[list(columns_to_add.keys()) + ['client_id']].rename(columns=columns_to_add)\n",
    "\n",
    "last_refresh_date = datetime.strptime(datetime.now().strftime('%Y-%m-%d'), '%Y-%m-%d')\n",
    "\n",
    "print(f'last_refresh_date: {last_refresh_date}')\n",
    "\n",
    "fact_sentinel_event_df = pd.merge(fact_sentinel_event_df, fact_last_visit_df, on='client_id', how='left')\n",
    "\n",
    "fact_sentinel_event_df['last_visit_duration'] = (fact_sentinel_event_df['last_next_visit_date'].dt.year - fact_sentinel_event_df['last_visit_date'].dt.year) * 12 + (fact_sentinel_event_df['last_next_visit_date'].dt.month - fact_sentinel_event_df['last_visit_date'].dt.month)\n",
    "\n",
    "fact_sentinel_event_df['iit_date'] = fact_sentinel_event_df['last_next_visit_date'] + pd.Timedelta(days=29)\n",
    "\n",
    "def diff_in_months(date1, date2):\n",
    "    if pd.isnull(date1) or pd.isnull(date2):\n",
    "        return None\n",
    "    return (date1.year - date2.year) * 12 + date1.month - date2.month\n",
    "\n",
    "fact_sentinel_event_df['months_since_hiv_confirmed'] = fact_sentinel_event_df.apply(lambda row: diff_in_months(last_refresh_date, row['hiv_confirmation_date']), axis=1)\n",
    "\n",
    "fact_sentinel_event_df['iit_duration'] = (pd.Timestamp('today').normalize() - fact_sentinel_event_df['iit_date']).dt.days\n",
    "\n",
    "fact_sentinel_event_df['last_PBFW'] = fact_sentinel_event_df.apply(\n",
    "    lambda row: 'Pregnant' if row['last_pregnancy_status'] == 'Yes' and row['sex'] == 'Female' else 'Breast feeding' if row['last_breast_feeding'] == 'Yes' and row['sex'] == 'Female' else None, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "fact_sentinel_event_df['last_PBFW_status'] = fact_sentinel_event_df.apply(\n",
    "    lambda row: 'Yes' if pd.notna(row['last_PBFW']) and row['sex'] == 'Female' else 'No' if row['sex'] == 'Female' else None,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "fact_sentinel_event_df.head()\n",
    "\n",
    "environment.log_message(f'Finished extracting client visits data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create patient regimen dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_reg_confs = {\n",
    "    \"query\": \"SELECT idpatient, idfacilitycreate, \\\"date\\\", type,line, code, dosage,duration, reason FROM rgm\",\n",
    "    \"cols\": ['client_id', 'ti_facility_id', 'regimen_date', 'regimen_type', 'regimen_line' ,'regimen', 'regimen_dosage','regimen_duration', 'regimen_reason']\n",
    "}\n",
    "\n",
    "fact_reg_query = fact_reg_confs.get(\"query\")\n",
    "fact_reg_cols = fact_reg_confs.get(\"cols\")\n",
    "\n",
    "fact_reg_data = fetch_file_maker_data(fact_reg_query, fm_connection)\n",
    "fact_reg_df = pd.DataFrame(fact_reg_data, columns=fact_reg_cols)\n",
    "\n",
    "fact_reg_df['regimen_date'] = pd.to_datetime(fact_reg_df['regimen_date'], errors='coerce')\n",
    "\n",
    "fact_reg_df = fact_reg_df.dropna(subset=['client_id', 'regimen_date'])\n",
    "\n",
    "fact_reg_df = fact_reg_df.loc[fact_reg_df.groupby('client_id')['regimen_date'].idxmax()]\n",
    "\n",
    "fact_reg_df.head()\n",
    "\n",
    "environment.log_message(f'Finished extracting client regimen data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add regimen info to fact_sentinel_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_add = ['client_id','regimen_line' ,'regimen','regimen_date']\n",
    "\n",
    "fact_reg_df = fact_reg_df[columns_to_add]\n",
    "\n",
    "fact_sentinel_event_df = pd.merge(fact_sentinel_event_df, fact_reg_df, on='client_id', how='left')\n",
    "\n",
    "fact_sentinel_event_df = fact_sentinel_event_df.rename(columns={\n",
    "    'regimen_line': 'last_regimen_line',\n",
    "    'regimen': 'last_regimen',\n",
    "    'regimen_date': 'last_regimen_date'\n",
    "})\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create fact_ti dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_ti_confs = {\n",
    "    \"query\": \"SELECT idpatient, idfacilitycreate, interruptionDate,interruptionReason, interruptionReasonOther, restartDate,duration FROM ti\",\n",
    "    \"cols\": ['client_id', 'ti_facility_id', 'art_interruption_date', 'art_interruption_reason', 'art_interruption_reason_other' ,'art_restart_date', 'interruption_duration']\n",
    "}\n",
    "\n",
    "fact_ti_query = fact_ti_confs.get(\"query\")\n",
    "fact_ti_cols = fact_ti_confs.get(\"cols\")\n",
    "\n",
    "fact_ti_data = fetch_file_maker_data(fact_ti_query, fm_connection)\n",
    "fact_ti_df = pd.DataFrame(fact_ti_data, columns=fact_ti_cols)\n",
    "\n",
    "fact_ti_df['art_restart_date'] = pd.to_datetime(fact_ti_df['art_restart_date'], errors='coerce')\n",
    "\n",
    "fact_ti_df = fact_ti_df.dropna(subset=['client_id', 'art_interruption_date'])\n",
    "\n",
    "fact_ti_df = fact_ti_df.loc[fact_ti_df.groupby('client_id')['art_interruption_date'].idxmax()]\n",
    "\n",
    "fact_ti_df.head()\n",
    "\n",
    "environment.log_message(f'Finished extracting client treatment interruption data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add treatment interription info to fact_sentinel_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_add = ['client_id', 'art_interruption_date', 'art_interruption_reason', 'art_interruption_reason_other' ,'art_restart_date']\n",
    "\n",
    "fact_ti_df = fact_ti_df[columns_to_add]\n",
    "\n",
    "fact_sentinel_event_df = pd.merge(fact_sentinel_event_df, fact_ti_df, on='client_id', how='left')\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create fact_tbt dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_tbt_confs = {\n",
    "    \"query\": \"SELECT idpatient, idfacilitycreate, category, startDate, regimen, duration, stopDateExpected, stopDateActual , registrationNumber , site, siteDetail , CASE  WHEN outcome = '1' THEN 'Cured' WHEN outcome = '2' THEN 'Treatment complete' WHEN outcome = '3' THEN 'Died' WHEN outcome = '4' THEN 'Failure' WHEN outcome = '5' THEN 'Lost to follow-up' WHEN outcome = '6' THEN 'Not evaluated' END AS outcome, devCreationTimestamp  FROM tbt\",\n",
    "    \"cols\": ['client_id', 'tbt_facility_id', 'tbt_category', 'tbt_start_date', 'tbt_regimen', 'tbt_duration' ,'tbt_expected_stop_date', 'tbt_actual_stop_date', 'tbt_registration_number', 'tbt_site', 'tbt_site_detail', 'tbt_outcome', 'tbt_outcome_date']\n",
    "}\n",
    "\n",
    "fact_tbt_query = fact_tbt_confs.get(\"query\")\n",
    "fact_tbt_cols = fact_tbt_confs.get(\"cols\")\n",
    "\n",
    "fact_tbt_data = fetch_file_maker_data(fact_tbt_query, fm_connection)\n",
    "fact_tbt_df = pd.DataFrame(fact_tbt_data, columns=fact_tbt_cols)\n",
    "\n",
    "fact_tbt_df['tbt_outcome_date'] = pd.to_datetime(fact_tbt_df['tbt_outcome_date'])\n",
    "fact_tbt_df['tbt_start_date'] = pd.to_datetime(fact_tbt_df['tbt_start_date'])\n",
    "fact_tbt_df['tbt_outcome_date'] = fact_tbt_df['tbt_outcome_date'].dt.date\n",
    "\n",
    "fact_tbt_df.loc[fact_tbt_df['tbt_outcome'].isnull(), 'tbt_outcome_date'] = None\n",
    "\n",
    "fact_tbt_df = fact_tbt_df.dropna(subset=['tbt_start_date'])\n",
    "\n",
    "fact_tbt_df = fact_tbt_df.loc[fact_tbt_df.groupby('client_id')['tbt_start_date'].idxmax()]\n",
    "\n",
    "fact_tbt_df.head()\n",
    "\n",
    "environment.log_message(f'Finished extracting client tbt data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add tbt info to fact_sentinel_event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_add = ['client_id', 'tbt_facility_id', 'tbt_category', 'tbt_start_date', 'tbt_regimen', 'tbt_duration' ,'tbt_expected_stop_date', 'tbt_actual_stop_date', 'tbt_registration_number', 'tbt_site', 'tbt_site_detail', 'tbt_outcome', 'tbt_outcome_date']\n",
    "\n",
    "fact_tbt_df = fact_tbt_df[columns_to_add]\n",
    "\n",
    "fact_sentinel_event_df = pd.merge(fact_sentinel_event_df, fact_tbt_df, on='client_id', how='left')\n",
    "fact_sentinel_event_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create fact_tpt dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_tpt_confs = {\n",
    "    \"query\": \"SELECT idpatient, idfacilitycreate, iptRegimen, startDate, duration, stopDateExpected, stopDateActual , CASE  WHEN stopReason = '1' THEN 'Completed TPT' WHEN stopReason = '2' THEN 'Cough' WHEN stopReason = '3' THEN 'Confirmed TB' WHEN stopReason = '4' THEN 'Hepatitis' WHEN stopReason = '5' THEN 'Neuropathy' WHEN stopReason = '6' THEN 'Poor Adherence' WHEN stopReason = '7' THEN 'Medicine Out Of Stock' WHEN stopReason = '8' THEN stopReasonOther ELSE '' END AS stopReason, status, adherenceDetail FROM ipt\",\n",
    "    \"cols\": ['client_id', 'tpt_facility_id', 'tpt_regimen', 'tpt_start_date', 'tpt_duration' ,'tpt_expected_stop_date', 'tpt_actual_stop_date', 'tpt_stop_reason', 'tpt_status', 'tpt_adherance']\n",
    "}\n",
    "\n",
    "fact_tpt_query = fact_tpt_confs.get(\"query\")\n",
    "fact_tpt_cols = fact_tpt_confs.get(\"cols\")\n",
    "\n",
    "fact_tpt_data = fetch_file_maker_data(fact_tpt_query, fm_connection)\n",
    "fact_tpt_df = pd.DataFrame(fact_tpt_data, columns=fact_tpt_cols)\n",
    "\n",
    "fact_tpt_df = fact_tpt_df.dropna(subset=['client_id', 'tpt_start_date'])\n",
    "\n",
    "fact_tpt_df = fact_tpt_df.loc[fact_tpt_df.groupby('client_id')['tpt_start_date'].idxmax()]\n",
    "\n",
    "fact_tpt_df['tpt_start_date'] = pd.to_datetime(fact_tpt_df['tpt_start_date'], errors='coerce')\n",
    "fact_tpt_df['tpt_actual_stop_date'] = pd.to_datetime(fact_tpt_df['tpt_actual_stop_date'], errors='coerce')\n",
    "fact_tpt_df['tpt_expected_stop_date'] = pd.to_datetime(fact_tpt_df['tpt_expected_stop_date'], errors='coerce')\n",
    "\n",
    "fact_tpt_df['tpt_duration_two'] = fact_tpt_df.apply(\n",
    "    lambda row: (row['tpt_expected_stop_date'] - row['tpt_start_date']).days \n",
    "                if pd.notna(row['tpt_expected_stop_date']) and pd.notna(row['tpt_start_date']) \n",
    "                else None,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "fact_tpt_df.loc[\n",
    "    (fact_tpt_df['tpt_regimen'] == '3H') & (fact_tpt_df['tpt_start_date'] > '2020-08-01'),\n",
    "    'tpt_regimen'\n",
    "] = '3HP'\n",
    "\n",
    "fact_tpt_df.head()\n",
    "\n",
    "environment.log_message(f'Finished extracting client tpt data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for invalid dates in the 'tpt_start_date' column\n",
    "invalid_dates = fact_tpt_df[pd.to_datetime(fact_tpt_df['tpt_expected_stop_date'], errors='coerce').isna()]\n",
    "\n",
    "# Display rows with invalid dates\n",
    "invalid_dates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add tpt info to fact_sentinel_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_add = ['client_id', 'tpt_facility_id', 'tpt_regimen', 'tpt_start_date', 'tpt_duration', 'tpt_duration_two' ,'tpt_expected_stop_date', 'tpt_actual_stop_date', 'tpt_stop_reason', 'tpt_status', 'tpt_adherance']\n",
    "\n",
    "fact_tpt_df = fact_tpt_df[columns_to_add]\n",
    "\n",
    "fact_sentinel_event_df = pd.merge(fact_sentinel_event_df, fact_tpt_df, on='client_id', how='left')\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute TPT Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_sentinel_event_df['tpt_type'] = fact_sentinel_event_df.apply(\n",
    "    lambda row: \"9H\" if pd.notna(row['tpt_start_date']) and row['tpt_duration_two'] >= 250 else\n",
    "                (\"6H\" if pd.notna(row['tpt_start_date']) and row['tpt_duration_two'] >= 168 else\n",
    "                 (\"3HP\" if pd.notna(row['tpt_start_date']) and row['tpt_start_date'] >= pd.to_datetime(\"2020-08-01\") and \n",
    "                          pd.notna(row['tpt_expected_stop_date']) and row['tpt_duration_two'] >= 77 else\n",
    "                  (\"3HP\" if row['tpt_regimen'] in [\"3H\", \"3HP\"] and row['tpt_start_date'] >= pd.to_datetime(\"2020-08-01\") else None))),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "fact_sentinel_event_df['tpt_type'] = fact_sentinel_event_df.apply(\n",
    "    lambda row: \"3HP\" if pd.isna(row['tpt_type']) and \n",
    "                          row['tpt_regimen'] in [\"3H\", \"3HP\"] and \n",
    "                          row['tpt_start_date'] >= pd.to_datetime(\"2020-08-01\") else row['tpt_type'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute tpt_status_two_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tpt_status_two_outcome(row):\n",
    "    # Define constants\n",
    "    tpt_complete_other = 146\n",
    "    tpt_complete_3HP = 70\n",
    "    tpt_on_tx_3H = 113\n",
    "    tpt_on_tx_other = 240\n",
    "\n",
    "    # Calculate the time differences for various conditions\n",
    "    start_to_actual_stop = (row['tpt_actual_stop_date'] - row['tpt_start_date']).days if pd.notna(row['tpt_actual_stop_date']) and pd.notna(row['tpt_start_date']) else None\n",
    "    start_to_last_refresh = (last_refresh_date - row['tpt_start_date']).days if pd.notna(row['tpt_start_date']) else None\n",
    "\n",
    "    if pd.isna(row['tpt_start_date']):\n",
    "        return \"No TPT Documentation\"\n",
    "    elif pd.notna(row['tpt_start_date']) and pd.notna(row['tpt_actual_stop_date']) and row['tpt_start_date'] >= row['tpt_actual_stop_date']:\n",
    "        return \"Wrong TPT Dates\"\n",
    "    elif pd.isna(row['tpt_start_date']) and pd.notna(row['tpt_actual_stop_date']):\n",
    "        return \"Wrong TPT Dates\"\n",
    "    elif pd.notna(row['tpt_start_date']) and pd.isna(row['tpt_regimen']) and pd.isna(row['tpt_expected_stop_date']) and pd.isna(row['tpt_actual_stop_date']):\n",
    "        return \"TPT regimen is blank\"\n",
    "    elif pd.notna(row['tpt_start_date']) and row['tpt_expected_stop_date'] == row['tpt_start_date'] and pd.isna(row['tpt_regimen']) and pd.isna(row['tpt_actual_stop_date']):\n",
    "        return \"TPT regimen is blank\"\n",
    "    elif pd.notna(row['tpt_start_date']) and row['tpt_expected_stop_date'] == row['tpt_start_date'] and pd.notna(row['tpt_regimen']) and row['tpt_regimen'] == \"Other\" and pd.isna(row['tpt_actual_stop_date']):\n",
    "        return \"TPT regimen is other\"\n",
    "    elif pd.isna(row['tpt_type']) and pd.notna(row['tpt_actual_stop_date']) and start_to_actual_stop >= tpt_complete_other:\n",
    "        return \"6-month TPT Completed but TPT Type is unknown\"\n",
    "    elif pd.isna(row['tpt_type']) and pd.isna(row['tpt_actual_stop_date']) and start_to_last_refresh >= tpt_complete_other:\n",
    "        return \"6-month TPT Completed but TPT Type is unknown\"\n",
    "    elif row['tpt_status'] == \"Active\" and row['tpt_type'] == \"3HP\" and pd.isna(row['tpt_actual_stop_date']) and start_to_last_refresh < tpt_on_tx_3H:\n",
    "     return \"Still on 3HP\"\n",
    "    elif row['tpt_status'] == \"Active\" and row['tpt_type'] == \"6H\" and pd.isna(row['tpt_actual_stop_date']) and start_to_last_refresh < tpt_on_tx_other:\n",
    "        return \"Still on 6H\"\n",
    "    elif row['tpt_status'] == \"Active\" and row['tpt_type'] == \"9H\" and pd.isna(row['tpt_actual_stop_date']) and start_to_last_refresh < tpt_on_tx_other:\n",
    "        return \"Still on 9H\"\n",
    "    elif row['tpt_type'] == \"3HP\" and pd.isna(row['tpt_actual_stop_date']) and start_to_last_refresh >= tpt_on_tx_3H:\n",
    "     return \"3HP Completed but TPT Stop Date is blank\"\n",
    "    elif row['tpt_type'] == \"3HP\" and start_to_actual_stop >= tpt_complete_3HP:\n",
    "     return \"3HP Completed\"\n",
    "    elif row['tpt_type'] == \"3HP\" and pd.notna(row['tpt_actual_stop_date']) and start_to_actual_stop < tpt_complete_3HP:\n",
    "     return \"3HP Stopped Before Completion\"\n",
    "    elif row['tpt_type'] == \"6H\" and pd.notna(row['tpt_actual_stop_date']) and start_to_actual_stop >= tpt_complete_other:\n",
    "        return \"6H Completed\"\n",
    "    elif row['tpt_type'] == \"6H\" and pd.isna(row['tpt_actual_stop_date']) and start_to_last_refresh >= tpt_on_tx_other:\n",
    "        return \"6H Completed but TPT Stop Date is blank\"\n",
    "    elif row['tpt_type'] == \"6H\" and pd.notna(row['tpt_actual_stop_date']) and start_to_actual_stop < tpt_complete_other:\n",
    "        return \"6H stopped Before 6-month Completion\"\n",
    "    elif row['tpt_type'] == \"9H\" and pd.notna(row['tpt_actual_stop_date']) and start_to_actual_stop >= tpt_complete_other:\n",
    "        return \"6-month of 9H Completed\"\n",
    "    elif row['tpt_type'] == \"9H\" and pd.isna(row['tpt_actual_stop_date']) and start_to_last_refresh >= tpt_on_tx_other:\n",
    "        return \"6-months of 9H Completed but TPT Stop Date is blank\"\n",
    "    elif row['tpt_type'] == \"9H\" and pd.notna(row['tpt_actual_stop_date']) and start_to_actual_stop < tpt_complete_other:\n",
    "        return \"9H stopped Before 6-month Completion\"\n",
    "    elif pd.isna(row['tpt_type']) and pd.notna(row['tpt_actual_stop_date']) and start_to_actual_stop < tpt_complete_other:\n",
    "        return \"TPT stopped before 6-month completion & TPT Type is unknown\"\n",
    "    elif pd.notna(row['tpt_start_date']) and row['tpt_start_date'] == row['tpt_expected_stop_date'] and pd.isna(row['tpt_actual_stop_date']):\n",
    "        return \"TPT regimen is blank\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "fact_sentinel_event_df['tpt_status_two_outcome'] = fact_sentinel_event_df.apply(compute_tpt_status_two_outcome, axis=1)\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create fact_lab dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_lab_confs = {\n",
    "    \"query\": \"SELECT l.idpatient, l.idfacilitycreate, l.orderDate, l.result, l.resultDate, lm.name, l.status FROM lab l INNER JOIN LabMaster lm ON lm.id=l.idtest\",\n",
    "    \"cols\": ['client_id', 'lab_facility_id', 'order_date', 'lab_result', 'result_date', 'test_name','status' ]\n",
    "}\n",
    "\n",
    "fact_lab_query = fact_lab_confs.get(\"query\")\n",
    "fact_lab_cols = fact_lab_confs.get(\"cols\")\n",
    "\n",
    "fact_lab_data = fetch_file_maker_data(fact_lab_query, fm_connection)\n",
    "fact_lab_df = pd.DataFrame(fact_lab_data, columns=fact_lab_cols)\n",
    "\n",
    "fact_lab_df['order_date'] = pd.to_datetime(fact_lab_df['order_date'], errors='coerce')\n",
    "fact_lab_df['result_date'] = pd.to_datetime(fact_lab_df['result_date'], errors='coerce')\n",
    "\n",
    "\n",
    "fact_lab_df.head()\n",
    "\n",
    "environment.log_message(f'Finished extracting client lab data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create fact_first_viral_load dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_first_viral_load_tests_df = fact_lab_df[fact_lab_df['test_name'] == 'Viral Load']\n",
    "fact_first_viral_load_tests_df = fact_first_viral_load_tests_df.sort_values('order_date').groupby('client_id').first().reset_index()\n",
    "\n",
    "def categorize_result(result):\n",
    "    if result < 40:\n",
    "        return 'Undetectable'\n",
    "    elif 40 <= result < 1000:\n",
    "        return 'LLV'\n",
    "    else:\n",
    "        return 'Unsuppressed'\n",
    "\n",
    "fact_first_viral_load_tests_df['category'] = fact_first_viral_load_tests_df['lab_result'].apply(categorize_result)\n",
    "\n",
    "fact_first_viral_load_tests_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create fact_last_viral_load dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_last_viral_load_tests_df = fact_lab_df[fact_lab_df['test_name'] == 'Viral Load']\n",
    "fact_last_viral_load_tests_df = fact_last_viral_load_tests_df.sort_values('order_date').groupby('client_id').last().reset_index()\n",
    "\n",
    "def categorize_result(result):\n",
    "    if result < 40:\n",
    "        return 'Undetectable'\n",
    "    elif 40 <= result < 1000:\n",
    "        return 'LLV'\n",
    "    else:\n",
    "        return 'Unsuppressed'\n",
    "\n",
    "fact_last_viral_load_tests_df['category'] = fact_last_viral_load_tests_df['lab_result'].apply(categorize_result)\n",
    "\n",
    "fact_last_viral_load_tests_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add first viral load info to fact_sentinel_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_add = {\n",
    "    'order_date': 'first_viral_load_order_date',\n",
    "    'result_date': 'first_viral_load_result_date', \n",
    "    'lab_result': 'first_viral_load_result',\n",
    "    'lab_facility_id': 'first_viral_load_facility_id',\n",
    "    'category': 'first_viral_load_result_category',\n",
    "    'status': 'first_viral_load_result_status',\n",
    "}\n",
    "\n",
    "fact_first_viral_load_tests_df = fact_first_viral_load_tests_df[list(columns_to_add.keys()) + ['client_id']].rename(columns=columns_to_add)\n",
    "\n",
    "fact_sentinel_event_df = pd.merge(fact_sentinel_event_df, fact_first_viral_load_tests_df, on='client_id', how='left')\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add last viral load info to fact_sentinel_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_add = {\n",
    "    'order_date': 'last_viral_load_order_date',\n",
    "    'result_date': 'last_viral_load_result_date', \n",
    "    'lab_result': 'last_viral_load_result',\n",
    "    'lab_facility_id': 'last_viral_load_facility_id',\n",
    "    'category': 'last_viral_load_result_category',\n",
    "    'status': 'last_viral_load_result_status',\n",
    "}\n",
    "\n",
    "fact_last_viral_load_tests_df = fact_last_viral_load_tests_df[list(columns_to_add.keys()) + ['client_id']].rename(columns=columns_to_add)\n",
    "\n",
    "fact_sentinel_event_df = pd.merge(fact_sentinel_event_df, fact_last_viral_load_tests_df, on='client_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add duration of ART in months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_in_months(date1, date2):\n",
    "    if pd.isnull(date1) or pd.isnull(date2):\n",
    "        return None\n",
    "    return (date1.year - date2.year) * 12 + date1.month - date2.month\n",
    "\n",
    "fact_sentinel_event_df['months_since_art_start'] = fact_sentinel_event_df.apply(lambda row: diff_in_months(last_refresh_date, row['art_start_date']), axis=1)\n",
    "\n",
    "fact_sentinel_event_df['months_since_art_restart'] = fact_sentinel_event_df.apply(lambda row: diff_in_months(last_refresh_date, row['art_restart_date']), axis=1)\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add program status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_status(row):\n",
    "    if (pd.notna(row['patient_status']) and\n",
    "        pd.notna(row['art_start_date']) and\n",
    "        row['patient_status'] == 'Active ART' and\n",
    "        (last_refresh_date - pd.to_datetime(row['art_start_date'])).days <= 31 and\n",
    "        (pd.isna(row['last_next_visit_date']) or pd.isna(row['last_visit_date']))):\n",
    "        return row['patient_status']\n",
    "    \n",
    "    elif (pd.notna(row['patient_status']) and\n",
    "          pd.isna(row['last_next_visit_date']) and\n",
    "          (last_refresh_date - pd.to_datetime(row['last_visit_date'])).days <= 365 and\n",
    "          row['patient_status'] == 'Active ART'):\n",
    "        return row['patient_status']\n",
    "    \n",
    "    elif (pd.notna(row['patient_status']) and row['patient_status'] == 'Deceased'):\n",
    "        return row['patient_status']\n",
    "    \n",
    "    elif (pd.notna(row['patient_status']) and row['patient_status'] == 'ART Stopped'):\n",
    "        return row['patient_status']\n",
    "    \n",
    "    elif (pd.notna(row['patient_status']) and row['patient_status'] == 'Transferred Out'):\n",
    "        return row['patient_status']\n",
    "    \n",
    "    elif (pd.notna(row['iit_date']) and\n",
    "          pd.to_datetime(row['iit_date']) > last_refresh_date and\n",
    "          (pd.notna(row['art_start_date']) or pd.notna(row['last_regimen']))):\n",
    "        return 'Active ART'\n",
    "    \n",
    "    elif (pd.notna(row['iit_date']) and\n",
    "          pd.to_datetime(row['iit_date']) <= last_refresh_date and\n",
    "          (pd.notna(row['art_start_date']) or pd.notna(row['last_regimen']))):\n",
    "        return 'IIT'\n",
    "    \n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "fact_sentinel_event_df['client_status'] = fact_sentinel_event_df.apply(classify_status, axis=1)\n",
    "\n",
    "fact_sentinel_event_df['tx_curr'] = fact_sentinel_event_df['client_status'].apply(\n",
    "    lambda status: 'Yes' if status == 'Active ART' else 'No'\n",
    ")\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Upto date on TPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "tpt_complete_other = 146\n",
    "tpt_complete_3HP = 70\n",
    "\n",
    "# Ensure the calculation happens for each row using apply\n",
    "fact_sentinel_event_df['up_to_date_tpt'] = fact_sentinel_event_df.apply(\n",
    "    lambda row: 1 if (\n",
    "        # Check if tx_curr is 'Yes'\n",
    "        row['tx_curr'] == 'Yes' and (\n",
    "            # Condition 1: TPT completed for 3HP\n",
    "            (pd.notna(row['tpt_actual_stop_date']) and pd.notna(row['tpt_start_date']) and\n",
    "             (row['tpt_actual_stop_date'] - row['tpt_start_date']).days >= tpt_complete_3HP and\n",
    "             row['tpt_type'] in [\"3HP\", \"3H\"]) or\n",
    "            # Condition 2: TPT completed for other regimens\n",
    "            (pd.notna(row['tpt_actual_stop_date']) and pd.notna(row['tpt_start_date']) and\n",
    "             (row['tpt_actual_stop_date'] - row['tpt_start_date']).days >= tpt_complete_other and\n",
    "             row['tpt_type'] in [\"6HP\", \"6H\", \"9H\", \"9HP\", None])  # None for not listed regimens\n",
    "        )\n",
    "    ) else 0,\n",
    "    axis=1\n",
    ")\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add currently on TPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "tpt_on_tx_3H = 113\n",
    "tpt_on_tx_other = 240\n",
    "\n",
    "# Update the DataFrame\n",
    "fact_sentinel_event_df['currently_on_tpt'] = fact_sentinel_event_df.apply(\n",
    "    lambda row: 1 if (\n",
    "        row['tx_curr'] == 'Yes' and (\n",
    "            # Condition 1: TPT initiated but not completed for 3HP or 3H\n",
    "            (pd.notna(row['tpt_start_date']) and pd.isna(row['tpt_actual_stop_date']) and\n",
    "             (last_refresh_date - row['tpt_start_date']).days < tpt_on_tx_3H and\n",
    "             row['tpt_type'] in [\"3HP\", \"3H\"]) or\n",
    "            # Condition 2: TPT initiated but not completed for 6H\n",
    "            (pd.notna(row['tpt_start_date']) and pd.isna(row['tpt_actual_stop_date']) and\n",
    "             (last_refresh_date - row['tpt_start_date']).days < tpt_on_tx_other and\n",
    "             row['tpt_type'] in [\"6H\",\"6HP\"]) or\n",
    "            # Condition 3: Currently on TB treatment (less than 1 year since TB treatment start)\n",
    "            (pd.notna(row['tbt_start_date']) and\n",
    "             (last_refresh_date - row['tbt_start_date']).days < 365.25 and \n",
    "             pd.isna(row['tbt_actual_stop_date']))\n",
    "        )\n",
    "    ) else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Display the updated DataFrame\n",
    "fact_sentinel_event_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Incomplete or Never Initiated TPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "tpt_on_tx_3H = 112\n",
    "tpt_on_tx_other = 239\n",
    "\n",
    "tpt_incomplete_tx_3H = 70\n",
    "tpt_incomplete_tx_other = 146\n",
    "\n",
    "# Calculate 'incomplete_or_never_initiated_tpt' column\n",
    "fact_sentinel_event_df['incomplete_or_never_initiated_tpt'] = fact_sentinel_event_df.apply(\n",
    "    lambda row: 1 if (\n",
    "        row['tx_curr'] == 'Yes' and (\n",
    "            # Condition 1: Initiation date is filled, but actual stop date is missing\n",
    "            (\n",
    "                pd.notna(row['tpt_start_date']) and pd.isna(row['tpt_actual_stop_date']) and (\n",
    "                    # >112 days for 3HP\n",
    "                    ((last_refresh_date - row['tpt_start_date']).days > tpt_on_tx_3H and\n",
    "                     row['tpt_type'] in [\"3HP\", \"3H\"]) or\n",
    "                    # >239 days for other regimens\n",
    "                    ((last_refresh_date - row['tpt_start_date']).days > tpt_on_tx_other and\n",
    "                     (row['tpt_type'] in [\"6HP\", \"6H\", \"9H\", \"9HP\"] or pd.isna(row['tpt_type'])))\n",
    "                )\n",
    "            ) or\n",
    "            # Condition 2: Actual stop date is filled, but duration is less than required\n",
    "            (\n",
    "                pd.notna(row['tpt_actual_stop_date']) and pd.notna(row['tpt_start_date']) and (\n",
    "                    # <70 days for 3HP\n",
    "                    ((row['tpt_actual_stop_date'] - row['tpt_start_date']).days < tpt_incomplete_tx_3H and\n",
    "                     row['tpt_type'] in [\"3HP\", \"3H\"]) or\n",
    "                    # <146 days for other regimens\n",
    "                    ((row['tpt_actual_stop_date'] - row['tpt_start_date']).days < tpt_incomplete_tx_other and\n",
    "                     (row['tpt_type'] in [\"6HP\", \"6H\", \"9H\", \"9HP\"] or pd.isna(row['tpt_type'])))\n",
    "                )\n",
    "            ) or\n",
    "            # Condition 3: No initiation date is filled, and not on TB treatment\n",
    "            (\n",
    "                pd.isna(row['tpt_start_date']) and (pd.isna(row['tbt_start_date']) or \n",
    "                (pd.notna(row['tbt_start_date']) and pd.notna(row['tbt_actual_stop_date'])))\n",
    "            ) or \n",
    "            # Condition 4: No TPT initiation date is filled, started on TB treatment, no completion date but been on TBT for more than 1 year\n",
    "            (\n",
    "                pd.isna(row['tpt_start_date']) and (pd.notna(row['tbt_start_date']) and pd.isna(row['tbt_actual_stop_date'])\n",
    "                and (last_refresh_date - row['tbt_start_date']).days > 365.25)\n",
    "            )\n",
    "        )\n",
    "    ) else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute tpt_status_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tpt_two_status(row):\n",
    "    if row['up_to_date_tpt'] == 1:\n",
    "        return 'TPT completed'\n",
    "    elif row['currently_on_tpt'] == 1:\n",
    "        return 'Currently on TPT/TBT'\n",
    "    elif row['incomplete_or_never_initiated_tpt'] == 1:\n",
    "        return 'Incomplete TPT'\n",
    "\n",
    "fact_sentinel_event_df['tpt_status_two'] = fact_sentinel_event_df.apply(calculate_tpt_two_status, axis=1)\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Retention for patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retention_status(row):\n",
    "    days_missed = (pd.to_datetime(last_refresh_date) - pd.to_datetime(row['last_next_visit_date'])).days if pd.notna(row['last_next_visit_date']) else None\n",
    "    \n",
    "    if row['tx_curr'] == 'Yes' and pd.notna(row['last_regimen']):\n",
    "        if pd.notna(row['last_next_visit_date']) and row['last_next_visit_date'] >= last_refresh_date:\n",
    "            return 'In Care'\n",
    "        elif pd.isna(row['last_next_visit_date']):\n",
    "            return 'In Care'\n",
    "        elif pd.notna(row['last_next_visit_date']) and row['last_next_visit_date'] < last_refresh_date and 1 <= days_missed <= 28:\n",
    "            return 'Missed Appointments'\n",
    "\n",
    "    if row['tx_curr'] == 'No' and pd.isna(row['art_start_date']):\n",
    "        if pd.notna(row['last_next_visit_date']) and row['last_next_visit_date'] >= last_refresh_date:\n",
    "            return 'In Care'\n",
    "        elif pd.notna(row['last_next_visit_date']) and row['last_next_visit_date'] < last_refresh_date and 1 <= days_missed <= 28:\n",
    "            return 'Missed Appointments'\n",
    "    \n",
    "    if pd.notna(row['last_next_visit_date']) and row['last_next_visit_date'] < last_refresh_date and 29 <= days_missed <= 90:\n",
    "        return 'Treatment Interruptions'\n",
    "    \n",
    "    return None\n",
    "\n",
    "fact_sentinel_event_df['retention_status'] = fact_sentinel_event_df.apply(retention_status, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add patient ages at different stages cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_sentinel_event_df['hiv_confirmation_age'] = (fact_sentinel_event_df['hiv_confirmation_date'] - fact_sentinel_event_df['date_of_birth']).dt.days // 365.25\n",
    "fact_sentinel_event_df['hiv_enrollment_age'] = (fact_sentinel_event_df['hiv_enrollment_date'] - fact_sentinel_event_df['date_of_birth']).dt.days // 365.25\n",
    "fact_sentinel_event_df['first_viral_load_result_age'] = (fact_sentinel_event_df['first_viral_load_result_date'] - fact_sentinel_event_df['date_of_birth']).dt.days // 365.25\n",
    "fact_sentinel_event_df['last_viral_load_result_age'] = (fact_sentinel_event_df['last_viral_load_result_date'] - fact_sentinel_event_df['date_of_birth']).dt.days // 365.25\n",
    "fact_sentinel_event_df['first_visit_age'] = (fact_sentinel_event_df['first_visit_date'] - fact_sentinel_event_df['date_of_birth']).dt.days // 365.25\n",
    "fact_sentinel_event_df['last_visit_age'] = (fact_sentinel_event_df['last_visit_date'] - fact_sentinel_event_df['date_of_birth']).dt.days // 365.25\n",
    "fact_sentinel_event_df['current_age'] = (last_refresh_date - fact_sentinel_event_df['date_of_birth']).dt.days // 365.25\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add ART Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_sentinel_event_df['art_duration'] = (\n",
    "    (last_refresh_date.year - fact_sentinel_event_df['art_start_date'].dt.year) * 12 +\n",
    "    (last_refresh_date.month - fact_sentinel_event_df['art_start_date'].dt.month)\n",
    ")\n",
    "\n",
    "fact_sentinel_event_df['art_duration'] = (last_refresh_date - fact_sentinel_event_df['art_start_date']).dt.days // 365.25\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Days since last visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_sentinel_event_df['days_since_last_visit'] = (last_refresh_date - fact_sentinel_event_df['last_visit_date']).dt.days\n",
    "fact_sentinel_event_df['years_since_last_visit'] = (last_refresh_date - fact_sentinel_event_df['last_visit_date']).dt.days // 365.25\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dim age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49, 54, 59, 64, float('inf')]\n",
    "labels = ['0-4', '5-9', '10-14','15-19','20-24','25-29','30-34','35-39','40-44','45-49','50-54','55-59','60-64', '65+']\n",
    "\n",
    "dim_age_group_df = pd.DataFrame({\n",
    "    'age': range(0, 101)\n",
    "})\n",
    "\n",
    "dim_age_group_df['pepfar_age_group'] = pd.cut(dim_age_group_df['age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "dim_age_group_df['paeds_adult_age_group'] = dim_age_group_df['age'].apply(lambda x: 'Pediatric' if x <= 19 else 'Adult')\n",
    "\n",
    "def tri_pillar_18_classify(age):\n",
    "    if 0 <= age <= 18:\n",
    "        return '0-18'\n",
    "    elif age == 19:\n",
    "        return '19'\n",
    "    elif 20 <= age <= 39:\n",
    "        return '20-39'\n",
    "    else:\n",
    "        return '40+'\n",
    "\n",
    "def tri_pillar_classify(age):\n",
    "    if 0 <= age <= 19:\n",
    "        return '0-19'\n",
    "    elif 20 <= age <= 39:\n",
    "        return '20-39'\n",
    "    else:\n",
    "        return '40+'\n",
    "    \n",
    "dim_age_group_df['tri_pillar_age_group_eighteen'] = dim_age_group_df['age'].apply(tri_pillar_18_classify)\n",
    "\n",
    "dim_age_group_df['tri_pillar_age_group'] = dim_age_group_df['age'].apply(tri_pillar_classify)\n",
    "\n",
    "dim_age_group_df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add age group sort column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tri_pillar_age_group_val(age):\n",
    "    if 0 <= age <= 19:\n",
    "        return 1\n",
    "    elif 20 <= age <= 39:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "dim_age_group_df['tri_pillar_age_group_val'] = dim_age_group_df['age'].apply(tri_pillar_age_group_val)\n",
    "\n",
    "dim_age_group_df['paeds_adult_age_group_val'] = dim_age_group_df['paeds_adult_age_group'].apply(\n",
    "    lambda x: 1 if x == '0-18 yr old (Pediatric)' else 2\n",
    ")\n",
    "\n",
    "def pepfar_age_group_val(label):\n",
    "    if label == '0-4':\n",
    "        return 1\n",
    "    elif label == '5-9':\n",
    "        return 2\n",
    "    elif label == '10-14':\n",
    "        return 3\n",
    "    elif label == '15-19':\n",
    "        return 4\n",
    "    elif label == '20-24':\n",
    "        return 5\n",
    "    elif label == '25-29':\n",
    "        return 6\n",
    "    elif label == '30-34':\n",
    "        return 7\n",
    "    elif label == '35-39':\n",
    "        return 8\n",
    "    elif label == '40-44':\n",
    "        return 9\n",
    "    elif label == '45-49':\n",
    "        return 10\n",
    "    elif label == '50-54':\n",
    "        return 11\n",
    "    elif label == '55-59':\n",
    "        return 12\n",
    "    elif label == '60-64':\n",
    "        return 13\n",
    "    else:  # '65+'\n",
    "        return 14\n",
    "\n",
    "dim_age_group_df['pepfar_age_group_val'] = dim_age_group_df['pepfar_age_group'].apply(pepfar_age_group_val)\n",
    "\n",
    "dim_age_group_df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a column that contains current age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_sentinel_event_df = fact_sentinel_event_df.merge(\n",
    "    dim_age_group_df[['age','pepfar_age_group', 'pepfar_age_group_val','paeds_adult_age_group', 'paeds_adult_age_group_val','tri_pillar_age_group','tri_pillar_age_group_val']], \n",
    "    left_on='current_age', \n",
    "    right_on='age', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the difference in months between last_refresh_date and last_viral_load_result_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_months_since_last_viral_load(date):\n",
    "    return (last_refresh_date.year - date.year) * 12 + last_refresh_date.month - date.month\n",
    "\n",
    "fact_sentinel_event_df['months_since_last_viral_load'] = fact_sentinel_event_df['last_viral_load_result_date'].apply(calculate_months_since_last_viral_load)\n",
    "fact_sentinel_event_df['months_since_last_viral_load_order'] = fact_sentinel_event_df['last_viral_load_order_date'].apply(calculate_months_since_last_viral_load)\n",
    "\n",
    "fact_sentinel_event_df['days_since_last_viral_load_order'] = (last_refresh_date - fact_sentinel_event_df['last_viral_load_order_date']).dt.days\n",
    "\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add VL Eligibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_vl_eligibility(row):\n",
    "    # Monitored per Guidelines\n",
    "    if row['tx_curr'] == 'Yes':\n",
    "        if row['months_since_art_start'] < 6 or row['months_since_art_restart'] < 6 :\n",
    "            return 'Monitored per Guidelines'\n",
    "\n",
    "        if row['last_viral_load_result'] >= 40 and row['months_since_last_viral_load'] <= 3:\n",
    "            return 'Monitored per Guidelines'\n",
    "\n",
    "        if (row['last_breast_feeding'] == 'Yes' or row['last_pregnancy_status'] == 'Yes') and row['months_since_last_viral_load'] <= 3:\n",
    "            return 'Monitored per Guidelines'\n",
    "\n",
    "        if row['current_age'] > 19 and row['last_breast_feeding'] != 'Yes' and row['last_pregnancy_status'] != 'Yes' and row['last_viral_load_result'] < 40 and row['months_since_last_viral_load'] <= 12:\n",
    "            return 'Monitored per Guidelines'\n",
    "\n",
    "        if row['current_age'] <= 19 and row['last_breast_feeding'] != 'Yes' and row['last_pregnancy_status'] != 'Yes' and row['last_viral_load_result'] < 40 and row['months_since_last_viral_load'] <= 6:\n",
    "            return 'Monitored per Guidelines'\n",
    "\n",
    "    # Slightly Delayed\n",
    "    if row['tx_curr'] == 'Yes':\n",
    "        if row['last_viral_load_result'] >= 40 and 3 < row['months_since_last_viral_load'] <= 4:\n",
    "            return 'Slightly Delayed'\n",
    "\n",
    "        if (row['last_breast_feeding'] == 'Yes' or row['last_pregnancy_status'] == 'Yes') and 3 < row['months_since_last_viral_load'] <= 4:\n",
    "            return 'Slightly Delayed'\n",
    "\n",
    "        if row['current_age'] > 19 and row['last_breast_feeding'] != 'Yes' and row['last_pregnancy_status'] != 'Yes' and row['last_viral_load_result'] < 40 and 12 < row['months_since_last_viral_load'] <= 14:\n",
    "            return 'Slightly Delayed'\n",
    "\n",
    "        if row['current_age'] <= 19 and row['last_breast_feeding'] != 'Yes' and row['last_pregnancy_status'] != 'Yes' and row['last_viral_load_result'] < 40 and 6 < row['months_since_last_viral_load'] <= 8:\n",
    "            return 'Slightly Delayed'\n",
    "                \n",
    "        # add patients with an order date and no result and the test was done in the last 14 days\n",
    "        if row['days_since_last_viral_load_order'] <= 14 and pd.isna(row['last_viral_load_result']):\n",
    "            return 'Slightly Delayed'\n",
    "\n",
    "    # Delayed\n",
    "    if row['tx_curr'] == 'Yes':\n",
    "        if row['last_viral_load_result'] >= 40 and row['months_since_last_viral_load'] > 4:\n",
    "            return 'Delayed'\n",
    "\n",
    "        if (row['last_breast_feeding'] == 'Yes' or row['last_pregnancy_status'] == 'Yes') and row['months_since_last_viral_load'] > 4:\n",
    "            return 'Delayed'\n",
    "\n",
    "        if row['current_age'] > 19 and row['last_breast_feeding'] != 'Yes' and row['last_pregnancy_status'] != 'Yes' and row['last_viral_load_result'] < 40 and row['months_since_last_viral_load'] > 14:\n",
    "            return 'Delayed'\n",
    "\n",
    "        if row['current_age'] <= 19 and row['last_breast_feeding'] != 'Yes' and row['last_pregnancy_status'] != 'Yes' and row['last_viral_load_result'] < 40 and row['months_since_last_viral_load'] > 8:\n",
    "            return 'Delayed'\n",
    "\n",
    "    # Default to Delayed if TxCurr is 'Yes' and no other conditions are met\n",
    "    if row['tx_curr'] == 'Yes':\n",
    "        return 'Delayed'\n",
    "\n",
    "    # If none of the conditions are met, return 'Not Classified'\n",
    "    return None\n",
    "\n",
    "\n",
    "fact_sentinel_event_df['vl_eligibility'] = fact_sentinel_event_df.apply(lambda row: classify_vl_eligibility(row), axis=1)\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add reason for next VL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_vl_reason(row):\n",
    "    if row['months_since_art_start'] is not None and row['months_since_art_start'] > 6 and pd.notnull(row['art_start_date']) and pd.isnull(row['first_viral_load_result_date']):\n",
    "        return 'First Test'\n",
    "    elif row['months_since_last_viral_load'] > 3 and row['last_pregnancy_status'] == 'Yes':\n",
    "        return 'Pregnant Women'\n",
    "    elif row['months_since_last_viral_load'] > 3 and row['last_breast_feeding'] == 'Yes':\n",
    "        return 'BF Women'\n",
    "    elif row['months_since_last_viral_load'] > 3 and row['last_viral_load_result_category'] == 'LLV':\n",
    "        return 'Low Level Viraemia'\n",
    "    elif row['months_since_last_viral_load'] > 6 and row['current_age'] <= 19:\n",
    "        return 'Children And Adolescents Under 19'\n",
    "    elif row['months_since_last_viral_load'] > 12 and row['current_age'] > 19:\n",
    "        return 'Treatment Monitoring For Adults'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "fact_sentinel_event_df['reason_for_next_vl'] = fact_sentinel_event_df.apply(categorize_vl_reason, axis=1)\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add next VL date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_next_vl_date(row):\n",
    "    if pd.isnull(row['last_viral_load_result_date']):\n",
    "        return None\n",
    "    elif row['reason_for_next_vl'] == 'First Test':\n",
    "        return row['last_viral_load_result_date'] + pd.DateOffset(months=6)\n",
    "    elif row['reason_for_next_vl'] == 'Pregnant Women':\n",
    "        return row['last_viral_load_result_date'] + pd.DateOffset(months=3)\n",
    "    elif row['reason_for_next_vl'] == 'BF Women':\n",
    "        return row['last_viral_load_result_date'] + pd.DateOffset(months=3)\n",
    "    elif row['reason_for_next_vl'] == 'Low Level Viraemia':\n",
    "        return row['last_viral_load_result_date'] + pd.DateOffset(months=6)\n",
    "    elif row['reason_for_next_vl'] == 'Children And Adolescents Under 19':\n",
    "        return row['last_viral_load_result_date'] + pd.DateOffset(months=6)\n",
    "    elif row['reason_for_next_vl'] == 'Treatment Monitoring For Adults':\n",
    "        return row['last_viral_load_result_date'] + pd.DateOffset(months=12)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "fact_sentinel_event_df['next_vl_date'] = fact_sentinel_event_df.apply(calculate_next_vl_date, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute if patient has ever been initiated on ART  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_has_been_initiated_on_art(row):\n",
    "    return 'Yes' if pd.notna(row['art_start_date']) else 'No'\n",
    "    \n",
    "fact_sentinel_event_df['has_ever_been_initiated_on_art'] = fact_sentinel_event_df.apply(lambda row: determine_has_been_initiated_on_art(row), axis=1)\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if last VL is valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_last_viral_load_valid(row, df):\n",
    "    row = df.iloc[row.name]\n",
    "\n",
    "    if pd.notna(row['last_viral_load_result_date']) and pd.notna(row['art_restart_date']):\n",
    "        if pd.to_datetime(row['last_viral_load_result_date']) < pd.to_datetime(row['art_restart_date']):\n",
    "            return 'No'\n",
    "        \n",
    "    if (row['tx_curr'] == 'Yes' and\n",
    "        row['last_PBFW_status'] == 'Yes' and\n",
    "        pd.notna(row['last_viral_load_result']) and\n",
    "        pd.notna(row['art_start_date']) and\n",
    "        (last_refresh_date - pd.to_datetime(row['art_start_date'])).days >= 90 and\n",
    "        row['vl_eligibility'] == 'Monitored per Guidelines'):\n",
    "        return 'Yes'\n",
    "\n",
    "    elif (row['tx_curr'] == 'Yes' and\n",
    "          (row['last_PBFW_status'] == 'No' or pd.isna(row['last_PBFW_status'])) and\n",
    "          row['current_age'] >= 20 and\n",
    "          pd.notna(row['last_viral_load_result']) and\n",
    "          pd.notna(row['art_start_date']) and\n",
    "          (last_refresh_date - pd.to_datetime(row['art_start_date'])).days >= 182 and\n",
    "          row['vl_eligibility'] == 'Monitored per Guidelines'):\n",
    "        return 'Yes'\n",
    "\n",
    "    elif (row['tx_curr'] == 'Yes' and\n",
    "          (row['last_PBFW_status'] == 'No' or pd.isna(row['last_PBFW_status'])) and\n",
    "          row['current_age'] <= 19 and\n",
    "          pd.notna(row['last_viral_load_result']) and\n",
    "          pd.notna(row['art_start_date']) and\n",
    "          (last_refresh_date - pd.to_datetime(row['art_start_date'])).days >= 182 and\n",
    "          row['vl_eligibility'] == 'Monitored per Guidelines'):\n",
    "        return 'Yes'\n",
    "        \n",
    "    else:\n",
    "        return 'No'\n",
    "    \n",
    "fact_sentinel_event_df['is_last_viral_load_valid'] = fact_sentinel_event_df.apply(is_last_viral_load_valid, axis=1, df=fact_sentinel_event_df)\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if patient is virally suppressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_is_virally_suppressed(row, df):\n",
    "    row = df.iloc[row.name]\n",
    "    if row['is_last_viral_load_valid'] == 'Yes' and row['last_viral_load_result_category'] == 'Undetectable':\n",
    "        return 'Yes'\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "fact_sentinel_event_df['is_virally_suppressed'] = fact_sentinel_event_df.apply(determine_is_virally_suppressed, axis=1, df=fact_sentinel_event_df)\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if patient is not virally suppressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_is_not_virally_suppressed(row, df):\n",
    "    row = df.iloc[row.name]\n",
    "    if row['is_last_viral_load_valid'] == 'Yes' and row['last_viral_load_result_category'] == 'Unsuppressed':\n",
    "        return 'Yes'\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "fact_sentinel_event_df['is_not_virally_suppressed'] = fact_sentinel_event_df.apply(determine_is_not_virally_suppressed, axis=1, df=fact_sentinel_event_df)\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute needs VL test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_needs_VL_test(row, df):\n",
    "    row = df.iloc[row.name]\n",
    "    if (row['months_since_art_start'] > 6 and pd.notna(row['first_viral_load_result_date']) and row['last_breast_feeding'] != 'Yes') and (row['is_not_virally_suppressed'] != 'Yes' and row['is_virally_suppressed'] != 'Yes'):\n",
    "        return 'Yes'\n",
    "    elif (row['last_viral_load_result_category'] == 'Undetectable' and row['last_next_visit_date'] >= last_refresh_date and row['months_since_last_viral_load'] > 12 and row['last_breast_feeding'] != 'Yes') and (row['is_not_virally_suppressed'] != 'Yes' and row['is_virally_suppressed'] != 'Yes'):\n",
    "        return 'Yes'\n",
    "    elif (row['last_viral_load_result_category'] == 'Unsuppressed' and row['last_next_visit_date'] >= last_refresh_date and row['months_since_last_viral_load'] > 3 and row['last_breast_feeding'] != 'Yes') and (row['is_not_virally_suppressed'] != 'Yes' and row['is_virally_suppressed'] != 'Yes'):\n",
    "        return 'Yes'\n",
    "    elif (row['months_since_art_start'] > 3 and pd.notna(row['first_viral_load_result_date']) and row['last_breast_feeding'] == 'Yes') and (row['is_not_virally_suppressed'] != 'Yes' and row['is_virally_suppressed'] != 'Yes'):\n",
    "        return 'Yes'\n",
    "    elif (row['last_viral_load_result_category'] == 'Undetectable' and row['last_next_visit_date'] >= last_refresh_date and row['months_since_last_viral_load'] > 6 and row['last_breast_feeding'] == 'Yes') and (row['is_not_virally_suppressed'] != 'Yes' and row['is_virally_suppressed'] != 'Yes'):\n",
    "        return 'Yes'\n",
    "    elif (row['last_viral_load_result_category'] == 'Unsuppressed' and row['last_next_visit_date'] >= last_refresh_date and row['months_since_last_viral_load'] > 3 and row['last_breast_feeding'] == 'Yes') and (row['is_not_virally_suppressed'] != 'Yes' and row['is_virally_suppressed'] != 'Yes'):\n",
    "        return 'Yes'\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "fact_sentinel_event_df['needs_vl_test'] = fact_sentinel_event_df.apply(determine_needs_VL_test, axis=1, df=fact_sentinel_event_df)\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign MMP Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_mmp(row,df):\n",
    "    row = df.iloc[row.name]\n",
    "    if (row['tx_curr'] == 'Yes' and \n",
    "        pd.notna(row['last_next_visit_date']) and \n",
    "        pd.notna(row['last_visit_date']) and\n",
    "        0 <= (pd.to_datetime(row['last_next_visit_date']) - pd.to_datetime(row['last_visit_date'])).days < 84):\n",
    "        return '< 3 MMP'\n",
    "    elif (row['tx_curr'] == 'Yes' and\n",
    "          pd.notna(row['last_next_visit_date']) and \n",
    "          pd.notna(row['last_visit_date']) and\n",
    "          84 <= (pd.to_datetime(row['last_next_visit_date']) - pd.to_datetime(row['last_visit_date'])).days < 168):\n",
    "        return '3-5 MMP'\n",
    "    elif (row['tx_curr'] == 'Yes' and\n",
    "          pd.notna(row['last_next_visit_date']) and\n",
    "          pd.notna(row['last_visit_date']) and\n",
    "          (pd.to_datetime(row['last_next_visit_date']) - pd.to_datetime(row['last_visit_date'])).days >= 168):\n",
    "        return '6+ MMP'\n",
    "    elif (row['tx_curr'] == 'Yes' and\n",
    "          pd.isna(row['last_next_visit_date'])):\n",
    "        return '6+ MMP'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "fact_sentinel_event_df['mmp_status'] = fact_sentinel_event_df.apply(assign_mmp, axis=1, df=fact_sentinel_event_df)\n",
    "\n",
    "fact_sentinel_event_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Six MMP Eligibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_six_mmp_eligibility(row, df):\n",
    "    row = df.iloc[row.name]\n",
    "    if (row['current_age'] > 2 and (pd.isnull(row['tbt_start_date']) or row['tbt_duration'] >= 6) and (row['is_last_viral_load_valid'] == 'Yes' and row['last_viral_load_result'] < 40) and row['months_since_art_start'] >= 6  and (row['last_regimen_line'] == '1' or row['last_regimen_line'] == '2') and pd.isnull(row['last_oi_other'])):\n",
    "        return 'Yes'\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "max_last_visit_month = last_refresh_date.month\n",
    "max_last_visit_year = last_refresh_date.year\n",
    "\n",
    "if max_last_visit_month == 1:  # Handle the edge case for January\n",
    "    prev_last_visit_month = 12\n",
    "    prev_last_visit_year = max_last_visit_year - 1\n",
    "else:\n",
    "    prev_last_visit_month = max_last_visit_month - 1\n",
    "    prev_last_visit_year = max_last_visit_year\n",
    "\n",
    "fact_sentinel_event_df['last_visit_month'] = fact_sentinel_event_df['last_visit_date'].dt.month\n",
    "fact_sentinel_event_df['last_visit_year'] = fact_sentinel_event_df['last_visit_date'].dt.year\n",
    "\n",
    "fact_sentinel_event_df['mmp_status_current'] = fact_sentinel_event_df.apply(\n",
    "    lambda row: row['mmp_status'] if (row['last_visit_month'] == prev_last_visit_month and row['last_visit_year'] == prev_last_visit_year) else None,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "fact_sentinel_event_df['mmp_status_adult'] = fact_sentinel_event_df['paeds_adult_age_group'].apply(lambda x: 'Yes' if 'adult' in str(x).lower() else None)\n",
    "\n",
    "fact_sentinel_event_df['mmp_status_paed'] = fact_sentinel_event_df['paeds_adult_age_group'].apply(lambda x: 'Yes' if 'pediatric' in str(x).lower() else None)\n",
    "\n",
    "fact_sentinel_event_df['six_mmp_eligible'] = fact_sentinel_event_df.apply(determine_six_mmp_eligibility, axis=1, df=fact_sentinel_event_df)\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Six MMP Eligibility But Not Given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_sentinel_event_df['six_mmp_eligible_but_not_given'] = fact_sentinel_event_df.apply(\n",
    "    lambda row: 'Yes' if row['six_mmp_eligible'] == 'Yes' and row['mmp_status'] != '6+ MMP' else 'No', \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute currrent cascade status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_art_outcomes(row):\n",
    "    if row['is_virally_suppressed'] == 'Yes':\n",
    "        return 'VL Suppressed'\n",
    "    elif row['is_not_virally_suppressed'] == 'Yes':\n",
    "        return 'VL Not Suppressed'\n",
    "    elif row['needs_vl_test'] == 'Yes':\n",
    "        return 'Needs VL Test'\n",
    "    elif row['months_since_art_start'] < 6:\n",
    "        return 'Recently initiated'\n",
    "    elif row['has_ever_been_initiated_on_art'] == 'No':\n",
    "        return 'Not initiated on ART'\n",
    "    elif row['years_since_last_visit'] > 2:\n",
    "        return 'Case Closed'\n",
    "    elif row['patient_status'] == 'Deceased':\n",
    "        return 'Died'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "fact_sentinel_event_df['art_outcomes'] = fact_sentinel_event_df.apply(determine_art_outcomes, axis=1)\n",
    "\n",
    "fact_sentinel_event_df.head()\n",
    "\n",
    "environment.log_message(f'Finished adding computed columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change dates from datetime to date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_sentinel_event_df = fact_sentinel_event_df.apply(lambda col: col.dt.date if col.dtype == 'datetime64[ns]' else col)\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reorder the columns in fact_sentinel_event_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_order = [\n",
    "    'client_id', 'region', 'district', 'facility_code', 'current_facility', 'id_facility_current',  'transfer_status', 'transfer_date',\n",
    "    'quantum_number', 'art_number', 'art_number_legacy', 'client_code', 'pharmacy_code', \n",
    "    'pmtct_number',  'first_name', 'last_name', 'contact_number', 'alt_contact_number', 'date_of_birth', 'sex', 'marital_status',  'current_age',  'pepfar_age_group', 'tri_pillar_age_group', 'paeds_adult_age_group', \n",
    "    'ts_name', 'ts_cell_phone_number', 'ts_second_name', 'ts_second_cell_phone_number',\n",
    "    'weight','current_town', 'current_constituency', 'current_street', 'permanent_town', 'permanent_constituency', 'permanent_street', \n",
    "    'cbart_cargs_name', 'cbart_cargs_code','hiv_confirmation_date', 'hiv_confirmation_age', 'hiv_confirmatory_result_date', 'hiv_confirmatory_result_type', 'hiv_diagnosis_facility_id',\n",
    "    'hiv_enrollment_date', 'hiv_enrollment_age','hiv_disclosure_enrollment_date', 'full_disclosure_date', 'hiv_enrollment_facility_id','arv_initiating_facility','art_start_date', 'months_since_art_start', 'months_since_art_restart','art_duration', 'has_ever_been_initiated_on_art', \n",
    "    'patient_status', 'who_stage', 'art_eligible_reason',  'first_visit_date', 'first_visit_age', 'first_visit_facility_id', 'last_visit_date', 'last_visit_age',  'last_next_visit_date', 'last_care_model', 'last_visit_facility_id', \n",
    "    'last_cc_treatment_type', 'last_cc_treatment_date', 'last_cc_results', 'last_oi', 'last_scheduled_visit_date', 'last_pregnancy_status', 'last_breast_feeding', \n",
    "    'last_oi_other', 'last_regimen_line', 'last_regimen', 'last_regimen_date', 'last_visit_duration', 'days_since_last_visit', 'years_since_last_visit', 'last_visit_month', 'last_visit_year',   'last_lmp', 'last_edd','last_tb_screen_result', 'first_viral_load_order_date', 'first_viral_load_result_date', 'first_viral_load_result_age',  \n",
    "    'first_viral_load_result', 'first_viral_load_facility_id', 'first_viral_load_result_category', 'first_viral_load_result_status', 'last_viral_load_order_date', \n",
    "    'last_viral_load_result_date','last_viral_load_result_age', 'months_since_last_viral_load', 'last_viral_load_result', 'last_viral_load_facility_id', 'is_virally_suppressed', 'is_not_virally_suppressed', 'needs_vl_test', 'last_viral_load_result_status', 'reason_for_next_vl', 'next_vl_date', \n",
    "    'art_interruption_date', 'art_interruption_reason', 'art_interruption_reason_other' ,'art_restart_date',\n",
    "    'tbt_start_date','tbt_regimen', 'tbt_expected_stop_date', 'tbt_actual_stop_date','tbt_facility_id', 'tbt_category',  'tbt_duration', 'tbt_registration_number', \n",
    "    'tbt_site', 'tbt_site_detail', 'tbt_outcome', 'tbt_outcome_date', 'tpt_facility_id', 'tpt_start_date', 'tpt_regimen', 'tpt_expected_stop_date', 'tpt_status','tpt_status_two_outcome','tpt_type',\n",
    "    'tpt_actual_stop_date', 'tpt_stop_reason',  'tpt_adherance','death_date', 'iit_date', 'iit_duration', 'client_status', 'retention_status', 'tx_curr', \n",
    "    'is_last_viral_load_valid', 'last_viral_load_result_category',  'vl_eligibility', 'tpt_duration', 'tpt_duration_two',  'tpt_status_two', 'last_PBFW', 'last_PBFW_status','mmp_status', 'mmp_status_current', 'mmp_status_adult', 'mmp_status_paed', 'six_mmp_eligible', 'six_mmp_eligible_but_not_given', 'art_outcomes'    \n",
    "]\n",
    "\n",
    "# Reorder the columns in the DataFrame\n",
    "fact_sentinel_event_df = fact_sentinel_event_df[new_column_order]\n",
    "\n",
    "# Display the reordered DataFrame\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(col):\n",
    "    if '_id' in col:\n",
    "        return '__' + col\n",
    "    else:\n",
    "        col = col.replace('_', ' ').title()\n",
    "        col = col.replace('Tpt', 'TPT')\n",
    "        col = col.replace('Tbt', 'TBT')\n",
    "        col = col.replace('Hiv', 'HIV')\n",
    "        col = col.replace('Art', 'ART')\n",
    "        col = col.replace('Iit', 'IIT')\n",
    "        col = col.replace('Mmp', 'MMP')\n",
    "        col = col.replace('Pmtct', 'PMTCT')\n",
    "        col = col.replace('Pbfw', 'PBFW')\n",
    "        col = col.replace('Vl', 'Viral Load')\n",
    "        col = col.replace('Tx Curr', 'TX Curr')\n",
    "        col = col.replace('Oi', 'OI')\n",
    "        col = col.replace('Lmp', 'LMP')\n",
    "        col = col.replace('Edd', 'EDD')\n",
    "        col = col.replace('Who', 'WHO')\n",
    "        col = col.replace('Tb', 'TB')\n",
    "        return col\n",
    "\n",
    "fact_sentinel_event_df.columns = [rename_columns(col) for col in fact_sentinel_event_df.columns]\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Destination Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostgreSQL server connection details\n",
    "server = destination_environment.get(\"server\")\n",
    "database = destination_environment.get(\"database\")\n",
    "port = destination_environment.get(\"port\")\n",
    "username = destination_environment.get(\"username\")\n",
    "password = destination_environment.get(\"password\")\n",
    "\n",
    "# Create connection to the default database (e.g., postgres) to check if the target database exists\n",
    "default_database = 'postgres'  # Usually, 'postgres' is used for administrative tasks\n",
    "default_connection_url = f'postgresql://{username}:{password}@{server}:{port}/{default_database}'\n",
    "\n",
    "# Set the isolation level to AUTOCOMMIT for creating the database\n",
    "default_engine = create_engine(default_connection_url, isolation_level='AUTOCOMMIT')\n",
    "\n",
    "# Query to check if the database exists\n",
    "check_db_query = f\"SELECT 1 FROM pg_database WHERE datname = '{database}'\"\n",
    "\n",
    "# Query to create the database if it doesn't exist\n",
    "create_db_query = f\"CREATE DATABASE {database}\"\n",
    "\n",
    "try:\n",
    "    with default_engine.connect() as connection:\n",
    "        # Check if the database exists\n",
    "        result = connection.execute(text(check_db_query)).fetchone()\n",
    "\n",
    "        if not result:\n",
    "            # If the database does not exist, create it\n",
    "            connection.execute(text(create_db_query))\n",
    "            environment.log_message(f\"Database '{database}' created successfully.\")\n",
    "        else:\n",
    "            environment.log_message(f\"Database '{database}' already exists.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")\n",
    "\n",
    "# Now connect to the target database\n",
    "connection_url = f'postgresql://{username}:{password}@{server}:{port}/{database}'\n",
    "engine = create_engine(connection_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function that checks if a table exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_and_insert_table(df, table_name, engine, schema_name):\n",
    "    \"\"\"\n",
    "    This function checks if a schema and table exist in the given schema. If the schema does not exist,\n",
    "    it creates the schema. If the table does not exist, it creates the table and inserts data from the\n",
    "    provided DataFrame. If the table exists, it replaces the data.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The DataFrame containing data to be inserted.\n",
    "    table_name (str): The name of the table to create or replace.\n",
    "    engine (sqlalchemy.engine.Engine): The SQLAlchemy engine to connect to the PostgreSQL database.\n",
    "    schema_name (str): The schema name where the table is located. Default is 'public'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # SQL query to check if the schema exists\n",
    "    check_schema_query = f\"\"\"\n",
    "    SELECT EXISTS (\n",
    "        SELECT 1 FROM information_schema.schemata \n",
    "        WHERE schema_name = '{schema_name}'\n",
    "    );\n",
    "    \"\"\"\n",
    "    \n",
    "    # SQL query to check if the table exists\n",
    "    check_table_query = f\"\"\"\n",
    "    SELECT EXISTS (\n",
    "        SELECT FROM information_schema.tables \n",
    "        WHERE table_schema = '{schema_name}' \n",
    "        AND table_name = '{table_name}'\n",
    "    );\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            # Begin a new transaction\n",
    "            with connection.begin() as transaction:\n",
    "                # Check if the schema exists\n",
    "                schema_exists = connection.execute(text(check_schema_query)).fetchone()\n",
    "\n",
    "                if not schema_exists[0]:  # If the schema doesn't exist\n",
    "                    environment.log_message(f\"Schema '{schema_name}' does not exist. Creating it...\")\n",
    "                    # Create the schema\n",
    "                    connection.execute(text(f\"CREATE SCHEMA IF NOT EXISTS {schema_name};\"))\n",
    "                    environment.log_message(f\"Schema '{schema_name}' created successfully.\")\n",
    "\n",
    "            # Check if the table exists (in a separate transaction to avoid conflicts)\n",
    "            with connection.begin() as transaction:\n",
    "                table_exists = connection.execute(text(check_table_query)).fetchone()\n",
    "\n",
    "                if not table_exists[0]:  # If the table doesn't exist\n",
    "                    environment.log_message(f\"Table '{table_name}' does not exist in schema '{schema_name}'. Creating it...\")\n",
    "                    # Automatically create the table based on the DataFrame structure\n",
    "                    df.to_sql(table_name, con=engine, if_exists='replace', index=False, schema=schema_name)\n",
    "                    environment.log_message(f\"Table '{table_name}' created and data inserted successfully.\")\n",
    "                else:\n",
    "                    # If the table exists, replace the data\n",
    "                    df.to_sql(table_name, con=engine, if_exists='replace', index=False, schema=schema_name)\n",
    "                    environment.log_message(f\"Data replaced successfully in table '{table_name}'.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write dim age group to table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'dim_age_group'\n",
    "schema_name = 'analysis'\n",
    "\n",
    "create_and_insert_table(dim_age_group_df, table_name, engine, schema_name)\n",
    "\n",
    "dim_age_group_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_views_sql = '''\n",
    "DROP VIEW IF EXISTS \"analysis\".\"score_card\";\n",
    "'''\n",
    "\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        with conn.begin():\n",
    "            conn.execute(text(drop_views_sql))\n",
    "            print(\"View dropped successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove NULL Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in problematic_columns:\n",
    "    fact_sentinel_event_df[col] = fact_sentinel_event_df[col].str.replace('\\x00', '', regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write sentinel event to table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'fact_sentinel_event'\n",
    "schema_name = 'analysis'\n",
    "\n",
    "create_and_insert_table(fact_sentinel_event_df, table_name, engine, schema_name)\n",
    "\n",
    "fact_sentinel_event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get current facility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facility_counts = dim_pat_df['current_facility'].value_counts()\n",
    "current_facility = facility_counts.idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add last refresh date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'last_refresh_date': [datetime.today().strftime('%Y-%m-%d')],\n",
    "    'facility_name': current_facility\n",
    "}\n",
    "\n",
    "last_refresh_date_df = pd.DataFrame(data)\n",
    "\n",
    "print(last_refresh_date_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write last refresh to table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'dim_last_refresh'\n",
    "schema_name = 'analysis'\n",
    "\n",
    "\n",
    "create_and_insert_table(last_refresh_date_df, table_name, engine, schema_name)\n",
    "\n",
    "last_refresh_date_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Score Card View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_score_card_creation_query = \"\"\"\n",
    "CREATE VIEW analysis.score_card AS\n",
    " WITH ordered_data AS (\n",
    "         SELECT '6+ MMP'::text AS indicator,\n",
    "            sum(\n",
    "                CASE\n",
    "                    WHEN fact_sentinel_event.\"TX Curr\" = 'Yes'::text AND fact_sentinel_event.\"MMP Status\" = '6+ MMP'::text THEN 1\n",
    "                    ELSE 0\n",
    "                END)::numeric * 100.0 / count(\n",
    "                CASE\n",
    "                    WHEN fact_sentinel_event.\"TX Curr\" = 'Yes'::text THEN 1\n",
    "                    ELSE NULL::integer\n",
    "                END)::numeric AS score,\n",
    "            1 AS order_col\n",
    "           FROM analysis.fact_sentinel_event\n",
    "        UNION ALL\n",
    "         SELECT 'TPT'::text AS indicator,\n",
    "            sum(\n",
    "                CASE\n",
    "                    WHEN fact_sentinel_event.\"TX Curr\" = 'Yes'::text AND fact_sentinel_event.\"TPT Status Two\" = 'TPT completed'::text THEN 1\n",
    "                    ELSE 0\n",
    "                END)::numeric * 100.0 / count(\n",
    "                CASE\n",
    "                    WHEN fact_sentinel_event.\"TX Curr\" = 'Yes'::text THEN 1\n",
    "                    ELSE NULL::integer\n",
    "                END)::numeric AS score,\n",
    "            2 AS order_col\n",
    "           FROM analysis.fact_sentinel_event\n",
    "        UNION ALL\n",
    "         SELECT 'Retention'::text AS indicator,\n",
    "            sum(\n",
    "                CASE\n",
    "                    WHEN (fact_sentinel_event.\"Retention Status\" = ANY (ARRAY['In Care'::text, 'Missed Appointments'::text])) THEN 1\n",
    "                    ELSE 0\n",
    "                END)::numeric * 100.0 / count(\n",
    "                CASE\n",
    "                    WHEN fact_sentinel_event.\"Retention Status\" = ANY (ARRAY['In Care'::text, 'Missed Appointments'::text, 'Treatment Interruptions'::text]) THEN 1\n",
    "                    ELSE NULL::integer\n",
    "                END)::numeric AS score,\n",
    "            3 AS order_col\n",
    "           FROM analysis.fact_sentinel_event\n",
    "        UNION ALL\n",
    "         SELECT 'VLM'::text AS indicator,\n",
    "            sum(\n",
    "                CASE\n",
    "                    WHEN fact_sentinel_event.\"TX Curr\" = 'Yes'::text AND (fact_sentinel_event.\"Viral Load Eligibility\" = ANY (ARRAY['Monitored per Guidelines'::text, 'Slightly Delayed'::text])) THEN 1\n",
    "                    ELSE 0\n",
    "                END)::numeric * 100.0 / count(\n",
    "                CASE\n",
    "                    WHEN fact_sentinel_event.\"TX Curr\" = 'Yes'::text THEN 1\n",
    "                    ELSE NULL::integer\n",
    "                END)::numeric AS score,\n",
    "            4 AS order_col\n",
    "           FROM analysis.fact_sentinel_event\n",
    "        UNION ALL\n",
    "         SELECT 'VLS (VL<40 CPS/ML)'::text AS indicator,\n",
    "            sum(\n",
    "                CASE\n",
    "                    WHEN fact_sentinel_event.\"TX Curr\" = 'Yes'::text AND fact_sentinel_event.\"Is Virally Suppressed\" = 'Yes'::text THEN 1\n",
    "                    ELSE 0\n",
    "                END)::numeric * 100.0 / count(\n",
    "                CASE\n",
    "                    WHEN fact_sentinel_event.\"TX Curr\" = 'Yes'::text AND fact_sentinel_event.\"Is Last Viral Load Valid\" = 'Yes'::text THEN 1\n",
    "                    ELSE NULL::integer\n",
    "                END)::numeric AS score,\n",
    "            5 AS order_col\n",
    "           FROM analysis.fact_sentinel_event\n",
    "        )\n",
    " SELECT indicator,\n",
    "    round(score, 2) AS score,\n",
    "        CASE\n",
    "            WHEN indicator = '6+ MMP'::text AND score < 50::numeric THEN 'Bad'::text\n",
    "            WHEN indicator = '6+ MMP'::text AND score >= 50::numeric AND score < 75::numeric THEN 'Average'::text\n",
    "            WHEN indicator = '6+ MMP'::text AND score >= 75::numeric THEN 'Good'::text\n",
    "            WHEN indicator = 'TPT'::text AND score < 85::numeric THEN 'Bad'::text\n",
    "            WHEN indicator = 'TPT'::text AND score >= 85::numeric AND score < 95::numeric THEN 'Average'::text\n",
    "            WHEN indicator = 'TPT'::text AND score >= 95::numeric THEN 'Good'::text\n",
    "            WHEN indicator = 'Retention'::text AND score < 90::numeric THEN 'Bad'::text\n",
    "            WHEN indicator = 'Retention'::text AND score >= 90::numeric AND score < 95::numeric THEN 'Average'::text\n",
    "            WHEN indicator = 'Retention'::text AND score >= 95::numeric THEN 'Good'::text\n",
    "            WHEN indicator = 'VLM'::text AND score < 80::numeric THEN 'Bad'::text\n",
    "            WHEN indicator = 'VLM'::text AND score >= 80::numeric AND score < 90::numeric THEN 'Average'::text\n",
    "            WHEN indicator = 'VLM'::text AND score >= 90::numeric THEN 'Good'::text\n",
    "            WHEN indicator = 'VLS (VL<40 CPS/ML)'::text AND score < 85::numeric THEN 'Bad'::text\n",
    "            WHEN indicator = 'VLS (VL<40 CPS/ML)'::text AND score >= 85::numeric AND score < 93::numeric THEN 'Average'::text\n",
    "            WHEN indicator = 'VLS (VL<40 CPS/ML)'::text AND score >= 93::numeric THEN 'Good'::text\n",
    "            ELSE 'Unknown'::text\n",
    "        END AS color\n",
    "   FROM ordered_data\n",
    "  ORDER BY order_col;\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        with conn.begin():\n",
    "            conn.execute(text(view_score_card_creation_query))\n",
    "            environment.log_message(\"Score Card view created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dim_pat_df\n",
    "del fact_hiv_diagnosis_df\n",
    "del fact_hiv_enrolment_df\n",
    "del fact_first_visit_df\n",
    "del fact_last_visit_df\n",
    "del fact_visits_df\n",
    "del fact_lab_df\n",
    "del fact_tpt_df\n",
    "del fact_meas_df\n",
    "del fact_first_viral_load_tests_df\n",
    "del fact_last_viral_load_tests_df\n",
    "del fact_tbt_df\n",
    "del fact_tsfr_df\n",
    "\n",
    "environment.log_message(f'Finished writing data to database')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log end time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Timestamp.today()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
